{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "authorship_tag": "ABX9TyP9pY0H6xZIragYqNIR35HI",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/viktorngkhnh/BearingData/blob/main/CNN_2D.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9MWUt3GkGaC1"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "import os\n",
        "import scipy.io\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from sklearn.metrics import confusion_matrix\n",
        "import seaborn as sns\n",
        "\n",
        "# Mount Drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "DATA_PATH = '/content/drive/My Drive/Bearing/DE_data'\n",
        "\n",
        "if os.path.exists(DATA_PATH):\n",
        "    print(f\"{DATA_PATH}\")\n",
        "    print(\"Fld:\", os.listdir(DATA_PATH))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# --- CELL 2: VISUALIZE RAW DATA (Soi d·ªØ li·ªáu th√¥) ---\n",
        "\n",
        "def plot_raw_sample(root_dir):\n",
        "    #Define\n",
        "    target_folders = [\"Normal\", \"Ball_007\", \"Ball_014\", \"Ball_021\", \"Ball_028\"]\n",
        "\n",
        "    plt.figure(figsize=(15, 10))\n",
        "    plt.subplots_adjust(hspace=0.4)\n",
        "\n",
        "    found_count = 0\n",
        "\n",
        "    # Check fld\n",
        "    if os.path.exists(root_dir):\n",
        "        all_folders = os.listdir(root_dir)\n",
        "\n",
        "        for i, target in enumerate(target_folders):\n",
        "\n",
        "            folder_name = next((f for f in all_folders if target in f), None)\n",
        "\n",
        "            if folder_name:\n",
        "                folder_path = os.path.join(root_dir, folder_name)\n",
        "                # Get .mat\n",
        "                files = [f for f in os.listdir(folder_path) if f.endswith('.mat')]\n",
        "\n",
        "                if files:\n",
        "                    file_path = os.path.join(folder_path, files[0])\n",
        "                    try:\n",
        "\n",
        "                        mat = scipy.io.loadmat(file_path)\n",
        "                        key = [k for k in mat.keys() if 'DE_time' in k][0]\n",
        "                        signal = mat[key].flatten()\n",
        "\n",
        "                        #plt.subplot(2, 2, i + 1)\n",
        "                        plt.figure(figsize=(15, 5))\n",
        "                        plt.ylim(-2 , 2)\n",
        "                        plt.plot(signal[:12000])\n",
        "                        plt.title(f\"{target} (File: {files[0]})\")\n",
        "                        plt.ylabel(\"Amplitude\")\n",
        "                        plt.grid(True)\n",
        "                        found_count += 1\n",
        "                    except Exception as e:\n",
        "                        print(f\"L·ªói ƒë·ªçc file {files[0]}: {e}\")\n",
        "            else:\n",
        "                print(f\"‚ö†Ô∏è Kh√¥ng th·∫•y folder n√†o ch·ª©a t√™n '{target}'\")\n",
        "\n",
        "    if found_count == 4:\n",
        "        print(\"‚úÖ ƒê√£ v·∫Ω ƒë·ªß 4 lo·∫°i t√≠n hi·ªáu. H√£y quan s√°t h√¨nh b√™n d∆∞·ªõi!\")\n",
        "    else:\n",
        "        print(f\"‚ö†Ô∏è Ch·ªâ t√¨m th·∫•y {found_count}/4 lo·∫°i d·ªØ li·ªáu.\")\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "plot_raw_sample(DATA_PATH)"
      ],
      "metadata": {
        "id": "QE71OtXxtmv1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def transform_1d_to_2d(signal, img_size=32):\n",
        "    \"\"\"\n",
        "    C·∫Øt t√≠n hi·ªáu 1D th√†nh c√°c ƒëo·∫°n v√† reshape th√†nh ma tr·∫≠n vu√¥ng (·∫£nh x√°m).\n",
        "    V√≠ d·ª•: 1024 m·∫´u -> (32, 32)\n",
        "    \"\"\"\n",
        "    window_size = 2 * img_size * img_size  # 32 * 32 * 2  = 2048\n",
        "\n",
        "    # 1. T√≠nh s·ªë l∆∞·ª£ng ·∫£nh c√≥ th·ªÉ t·∫°o ra (b·ªè ph·∫ßn d∆∞ cu·ªëi c√πng)\n",
        "    num_images = len(signal) // window_size\n",
        "\n",
        "    # 2. C·∫Øt b·ªè ph·∫ßn d∆∞ ƒë·ªÉ ƒë·∫£m b·∫£o chia h·∫øt cho 1024\n",
        "    truncated_signal = signal[:num_images * window_size]\n",
        "\n",
        "    # 3. Reshape sang (S·ªë l∆∞·ª£ng ·∫£nh, 32, 32)\n",
        "    images_2d = truncated_signal.reshape(-1, img_size, img_size)\n",
        "\n",
        "    # 4. Th√™m m·ªôt chi·ªÅu (Channel) ƒë·ªÉ PyTorch/CNN hi·ªÉu l√† ·∫£nh x√°m (N, 1, 32, 32)\n",
        "    images_2d = np.expand_dims(images_2d, axis=1)\n",
        "\n",
        "    return images_2d\n"
      ],
      "metadata": {
        "id": "chn2JPf_t4ZK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from scipy import signal\n",
        "\n",
        "def plot_spectrograms(root_dir):\n",
        "    target_folders = [\"Normal\", \"Ball_007\", \"Ball_014\", \"Ball_021\"]\n",
        "    plt.figure(figsize=(18, 12))\n",
        "\n",
        "    found_count = 0\n",
        "    all_folders = os.listdir(root_dir)\n",
        "\n",
        "    for i, target in enumerate(target_folders):\n",
        "        folder_name = next((f for f in all_folders if target in f), None)\n",
        "        if folder_name:\n",
        "            folder_path = os.path.join(root_dir, folder_name)\n",
        "            files = [f for f in os.listdir(folder_path) if f.endswith('.mat')]\n",
        "\n",
        "            if files:\n",
        "                file_path = os.path.join(folder_path, files[0])\n",
        "                mat = scipy.io.loadmat(file_path)\n",
        "                key = [k for k in mat.keys() if 'DE_time' in k][0]\n",
        "                sig = mat[key].flatten()[:120000] # L·∫•y m·ªôt ƒëo·∫°n ng·∫Øn ƒë·ªÉ v·∫Ω\n",
        "\n",
        "                # --- B∆Ø·ªöC QUAN TR·ªåNG: T·∫†O SPECTROGRAM ---\n",
        "                # fs: t·∫ßn s·ªë l·∫•y m·∫´u (CWRU th∆∞·ªùng l√† 12000 ho·∫∑c 48000 Hz)\n",
        "                fs = 12000\n",
        "                frequencies, times, Sxx = signal.spectrogram(sig, fs=fs, nperseg=512)\n",
        "\n",
        "                plt.subplot(2, 2, i + 1)\n",
        "                # D√πng pcolormesh ƒë·ªÉ v·∫Ω ma tr·∫≠n 2D\n",
        "                plt.pcolormesh(times, frequencies, 10 * np.log10(Sxx), shading='gouraud', cmap='jet')\n",
        "                plt.title(f\"Spectrogram: {target}\")\n",
        "                plt.ylabel(\"Frequency [Hz]\")\n",
        "                plt.xlabel(\"Time [sec]\")\n",
        "                plt.colorbar(label=\"Intensity [dB]\")\n",
        "                found_count += 1\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "# G·ªçi h√†m ƒë·ªÉ xem k·∫øt qu·∫£\n",
        "plot_spectrograms(DATA_PATH)"
      ],
      "metadata": {
        "id": "1hmzqR2FuTwu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2 # Th∆∞ vi·ªán x·ª≠ l√Ω ·∫£nh\n",
        "\n",
        "def get_spectrogram_image(sig, fs=12000, img_size=64):\n",
        "    # 1. T·∫°o Spectrogram th√¥\n",
        "    freqs, times, Sxx = signal.spectrogram(sig, fs=fs, nperseg=256)\n",
        "\n",
        "    # 2. Chuy·ªÉn sang thang ƒëo Log ƒë·ªÉ n·ªïi b·∫≠t ƒë·∫∑c tr∆∞ng\n",
        "    Sxx_log = 10 * np.log10(Sxx + 1e-10) # Th√™m s·ªë nh·ªè ƒë·ªÉ tr√°nh l·ªói log(0)\n",
        "\n",
        "    # 3. Chu·∫©n h√≥a v·ªÅ kho·∫£ng [0, 255] ƒë·ªÉ th√†nh ·∫£nh x√°m chu·∫©n\n",
        "    Sxx_norm = cv2.normalize(Sxx_log, None, 0, 255, cv2.NORM_MINMAX)\n",
        "    Sxx_norm = Sxx_norm.astype(np.uint8)\n",
        "\n",
        "    # 4. Resize v·ªÅ k√≠ch th∆∞·ªõc c·ªë ƒë·ªãnh (v√≠ d·ª• 64x64)\n",
        "    img_resized = cv2.resize(Sxx_norm, (img_size, img_size))\n",
        "\n",
        "    return img_resized\n",
        "\n",
        "# --- TH·ª∞C H√ÄNH TH·ª¨ ---\n",
        "# img = get_spectrogram_image(signal)\n",
        "# plt.imshow(img, cmap='jet')\n",
        "# print(f\"K√≠ch th∆∞·ªõc ·∫£nh m·ªõi: {img.shape}\")"
      ],
      "metadata": {
        "id": "Wf0nN9Kwv22R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class BearingSpectrogramDataset(Dataset):\n",
        "    def __init__(self, root_dir, window_size=2048, stride=512, img_size=64):\n",
        "        self.samples = []\n",
        "        self.labels = []\n",
        "        self.img_size = img_size\n",
        "\n",
        "        target_folders = [\"Normal\", \"Ball_007\", \"Ball_014\", \"Ball_021\", \"Ball_028\"]\n",
        "        label_map = {name: i for i, name in enumerate(target_folders)}\n",
        "\n",
        "        all_folders = os.listdir(root_dir)\n",
        "        for folder in all_folders:\n",
        "            match = next((t for t in target_folders if t in folder), None)\n",
        "            if match:\n",
        "                label = label_map[match]\n",
        "                folder_path = os.path.join(root_dir, folder)\n",
        "                files = [f for f in os.listdir(folder_path) if f.endswith('.mat')]\n",
        "\n",
        "                for file in files:\n",
        "                    file_path = os.path.join(folder_path, file)\n",
        "                    mat = scipy.io.loadmat(file_path)\n",
        "\n",
        "                    key = [k for k in mat.keys() if 'time' in k and ('DE' in k or 'FE' in k)][0]\n",
        "                    signal_full = mat[key].flatten()\n",
        "\n",
        "                    # K·ª∏ THU·∫¨T OVERLAPPING:\n",
        "                    # Thay v√¨ nh·∫£y b∆∞·ªõc b·∫±ng window_size, ta nh·∫£y b∆∞·ªõc b·∫±ng stride (nh·ªè h∆°n)\n",
        "                    # N·∫øu window=2048 v√† stride=512, ta s·∫Ω c√≥ g·∫•p 4 l·∫ßn d·ªØ li·ªáu\n",
        "                    idx = 0\n",
        "                    count_per_file = 0\n",
        "                    while idx + window_size <= len(signal_full):\n",
        "                        segment = signal_full[idx : idx + window_size]\n",
        "\n",
        "                        # T·∫°o Spectrogram\n",
        "                        f, t, Sxx = signal.spectrogram(segment, fs=12000)\n",
        "                        Sxx_log = 10 * np.log10(Sxx + 1e-10)\n",
        "                        Sxx_norm = cv2.normalize(Sxx_log, None, 0, 255, cv2.NORM_MINMAX).astype(np.uint8)\n",
        "                        img = cv2.resize(Sxx_norm, (img_size, img_size))\n",
        "\n",
        "                        self.samples.append(img)\n",
        "                        self.labels.append(label)\n",
        "\n",
        "                        idx += stride # Nh·∫£y m·ªôt b∆∞·ªõc ng·∫Øn\n",
        "                        count_per_file += 1\n",
        "\n",
        "                        # Gi·ªõi h·∫°n ƒë·ªÉ tr√°nh qu√° t·∫£i RAM n·∫øu c·∫ßn (v√≠ d·ª• 1000 ·∫£nh/file)\n",
        "                        if count_per_file >= 1000: break\n",
        "\n",
        "        self.samples = np.array(self.samples)\n",
        "        self.labels = np.array(self.labels)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.samples)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        img = torch.tensor(self.samples[idx], dtype=torch.float32).unsqueeze(0) / 255.0\n",
        "        label = torch.tensor(self.labels[idx], dtype=torch.long)\n",
        "        return img, label\n",
        "\n",
        "# Kh·ªüi t·∫°o l·∫°i v·ªõi stride=512 (Overlap 75%)\n",
        "dataset_overlap = BearingSpectrogramDataset(DATA_PATH, window_size=2048, stride=512)\n",
        "train_loader = DataLoader(dataset_overlap, batch_size=32, shuffle=True)\n",
        "\n",
        "print(f\"üöÄ S·ªë l∆∞·ª£ng ·∫£nh sau khi Overlap: {len(dataset_overlap)}\")"
      ],
      "metadata": {
        "id": "SeLMnaaMwHfh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from collections import Counter\n",
        "label_counts = Counter(dataset.labels)\n",
        "target_folders = [\"Normal\", \"Ball_007\", \"Ball_014\", \"Ball_021\", \"Ball_028\"]\n",
        "\n",
        "print(\"Ph√¢n b·ªï d·ªØ li·ªáu:\")\n",
        "for i, name in enumerate(target_folders):\n",
        "    print(f\"- {name}: {label_counts[i]} ·∫£nh\")"
      ],
      "metadata": {
        "id": "WR8aojbeCxqq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "\n",
        "class BearingCNN(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(BearingCNN, self).__init__()\n",
        "        # Convolutional Layer 1: In Gray layers\n",
        "        self.conv1 = nn.Conv2d(1, 16, kernel_size=3, padding=1)\n",
        "        self.pool = nn.MaxPool2d(2, 2)\n",
        "\n",
        "        # Convolutional Layer 2: In 16channels Out 32chanels\n",
        "        self.conv2 = nn.Conv2d(16, 32, kernel_size=3, padding=1)\n",
        "\n",
        "        # Pooling 2times 64x64 to 16x16\n",
        "        # Flatten layer: 32 channels * 16 * 16 = 8192 nodes\n",
        "        self.fc1 = nn.Linear(32 * 16 * 16, 128)\n",
        "        self.fc2 = nn.Linear(128, 5)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.pool(F.relu(self.conv1(x)))\n",
        "        x = self.pool(F.relu(self.conv2(x)))\n",
        "        x = x.view(-1, 32 * 16 * 16)\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = self.fc2(x)\n",
        "        return x\n",
        "\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model = BearingCNN().to(device)\n",
        "\n",
        "print(f\"‚úÖ ƒê√£ ƒë·ªãnh nghƒ©a v√† kh·ªüi t·∫°o 'model' tr√™n {device} th√†nh c√¥ng!\")"
      ],
      "metadata": {
        "id": "ILUOA_IGFlbg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "\n",
        "# 1. C·∫•u h√¨nh c√°c th√¥ng s·ªë\n",
        "num_epochs = 15\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "# Chuy·ªÉn m√¥ h√¨nh sang GPU/CPU\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model.to(device)\n",
        "\n",
        "print(f\"üöÄ B·∫Øt ƒë·∫ßu hu·∫•n luy·ªán 15 epochs tr√™n thi·∫øt b·ªã: {device}\")\n",
        "start_time = time.time()\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    model.train() # Chuy·ªÉn sang ch·∫ø ƒë·ªô hu·∫•n luy·ªán\n",
        "    running_loss = 0.0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "\n",
        "    for inputs, labels in train_loader:\n",
        "\n",
        "        inputs, labels = inputs.to(device), labels.to(device)\n",
        "\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # Forward pass\n",
        "        outputs = model(inputs)\n",
        "        loss = criterion(outputs, labels)\n",
        "\n",
        "        # Backward pass\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "\n",
        "        running_loss += loss.item()\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "\n",
        "    epoch_loss = running_loss / len(train_loader)\n",
        "    epoch_acc = 100 * correct / total\n",
        "\n",
        "    print(f\"Epoch [{epoch+1:02d}/{num_epochs}] - Loss: {epoch_loss:.4f} - Accuracy: {epoch_acc:.2f}%\")\n",
        "\n",
        "end_time = time.time()\n",
        "print(f\"\\n‚úÖ Ho√†n th√†nh hu·∫•n luy·ªán trong: {(end_time - start_time)/60:.2f} ph√∫t\")"
      ],
      "metadata": {
        "id": "JZtHuf_hEGyw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import seaborn as sns\n",
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "def plot_confusion_matrix(model, loader):\n",
        "    model.eval()\n",
        "    all_preds = []\n",
        "    all_labels = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for inputs, labels in loader:\n",
        "            inputs = inputs.to(device)\n",
        "            outputs = model(inputs)\n",
        "            _, preds = torch.max(outputs, 1)\n",
        "            all_preds.extend(preds.cpu().numpy())\n",
        "            all_labels.extend(labels.cpu().numpy())\n",
        "\n",
        "    cm = confusion_matrix(all_labels, all_preds)\n",
        "    plt.figure(figsize=(10, 8))\n",
        "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n",
        "                xticklabels=target_folders, yticklabels=target_folders)\n",
        "    plt.xlabel('(Predicted)')\n",
        "    plt.ylabel('(Actual)')\n",
        "    plt.title('Confusion Matrix')\n",
        "    plt.show()\n",
        "\n",
        "plot_confusion_matrix(model, train_loader)"
      ],
      "metadata": {
        "id": "_uW020G2GnCh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Thay ƒë·ªïi ƒë∆∞·ªùng d·∫´n n√†y t·ªõi th∆∞ m·ª•c FE c·ªßa b·∫°n\n",
        "DATA_PATH_FE = '/content/drive/My Drive/Bearing/FE_data'\n",
        "\n",
        "if os.path.exists(DATA_PATH_FE):\n",
        "    print(\"‚úÖ ƒê√£ t√¨m th·∫•y d·ªØ li·ªáu FE ƒë·ªÉ test!\")\n",
        "else:\n",
        "    print(\"‚ùå ƒê∆∞·ªùng d·∫´n FE kh√¥ng ƒë√∫ng, h√£y ki·ªÉm tra l·∫°i!\")"
      ],
      "metadata": {
        "id": "IGuXXA9pHFpR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Kh·ªüi t·∫°o dataset cho FE\n",
        "# Ch√∫ng ta v·∫´n d√πng window_size v√† img_size gi·ªëng nh∆∞ l√∫c train (2048 v√† 64)\n",
        "test_dataset_fe = BearingSpectrogramDataset(DATA_PATH_FE, window_size=2048, img_size=64)\n",
        "test_loader_fe = DataLoader(test_dataset_fe, batch_size=32, shuffle=False)\n",
        "\n",
        "print(f\"T·ªïng s·ªë ·∫£nh Spectrogram t·∫°o t·ª´ FE: {len(test_dataset_fe)}\")"
      ],
      "metadata": {
        "id": "nAMEQ5lFHYAP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.eval() # Chuy·ªÉn m√¥ h√¨nh sang ch·∫ø ƒë·ªô ƒë√°nh gi√° (quan tr·ªçng!)\n",
        "correct = 0\n",
        "total = 0\n",
        "\n",
        "all_preds = []\n",
        "all_labels = []\n",
        "\n",
        "with torch.no_grad(): # Kh√¥ng t√≠nh to√°n gradient ƒë·ªÉ ti·∫øt ki·ªám RAM\n",
        "    for inputs, labels in test_loader_fe:\n",
        "        inputs, labels = inputs.to(device), labels.to(device)\n",
        "        outputs = model(inputs)\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "        all_preds.extend(predicted.cpu().numpy())\n",
        "        all_labels.extend(labels.cpu().numpy())\n",
        "\n",
        "accuracy_fe = 100 * correct / total\n",
        "print(f\"üìä ƒê·ªô ch√≠nh x√°c (Accuracy) tr√™n t·∫≠p FE: {accuracy_fe:.2f}%\")"
      ],
      "metadata": {
        "id": "K1tPC35CHbrK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cm_fe = confusion_matrix(all_labels, all_preds)\n",
        "plt.figure(figsize=(10, 8))\n",
        "sns.heatmap(cm_fe, annot=True, fmt='d', cmap='Oranges',\n",
        "            xticklabels=target_folders, yticklabels=target_folders)\n",
        "plt.title('Confusion Matrix - Testing on FE Data')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "CwP1EVNYHfYw"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}