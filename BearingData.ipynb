{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "authorship_tag": "ABX9TyOdqD+YsLhkyZemepTAQ17i",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/viktorngkhnh/BearingData/blob/main/BearingData.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "import os\n",
        "import scipy.io\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from sklearn.metrics import confusion_matrix\n",
        "import seaborn as sns\n",
        "\n",
        "# Mount Drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "DATA_PATH = '/content/drive/My Drive/Bearing'\n",
        "\n",
        "if os.path.exists(DATA_PATH):\n",
        "    print(f\"{DATA_PATH}\")\n",
        "    print(\"Fld:\", os.listdir(DATA_PATH))"
      ],
      "metadata": {
        "id": "wDt_8jAWL3mn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# --- CELL 2: VISUALIZE RAW DATA (Soi d·ªØ li·ªáu th√¥) ---\n",
        "\n",
        "def plot_raw_sample(root_dir):\n",
        "    #Define\n",
        "    target_folders = [\"Normal\", \"Ball_007\", \"Ball_014\", \"Ball_021\", \"Ball_028\"]\n",
        "\n",
        "    plt.figure(figsize=(15, 10))\n",
        "    plt.subplots_adjust(hspace=0.4)\n",
        "\n",
        "    found_count = 0\n",
        "\n",
        "    # Check fld\n",
        "    if os.path.exists(root_dir):\n",
        "        all_folders = os.listdir(root_dir)\n",
        "\n",
        "        for i, target in enumerate(target_folders):\n",
        "\n",
        "            folder_name = next((f for f in all_folders if target in f), None)\n",
        "\n",
        "            if folder_name:\n",
        "                folder_path = os.path.join(root_dir, folder_name)\n",
        "                # Get .mat\n",
        "                files = [f for f in os.listdir(folder_path) if f.endswith('.mat')]\n",
        "\n",
        "                if files:\n",
        "                    file_path = os.path.join(folder_path, files[0])\n",
        "                    try:\n",
        "\n",
        "                        mat = scipy.io.loadmat(file_path)\n",
        "                        key = [k for k in mat.keys() if 'DE_time' in k][0]\n",
        "                        signal = mat[key].flatten()\n",
        "\n",
        "                        #plt.subplot(2, 2, i + 1)\n",
        "                        plt.figure(figsize=(15, 5))\n",
        "                        plt.ylim(-2 , 2)\n",
        "                        plt.plot(signal[:12000])\n",
        "                        plt.title(f\"M·∫´u: {target} (File: {files[0]})\")\n",
        "                        plt.ylabel(\"Bi√™n ƒë·ªô (Amplitude)\")\n",
        "                        plt.grid(True)\n",
        "                        found_count += 1\n",
        "                    except Exception as e:\n",
        "                        print(f\"L·ªói ƒë·ªçc file {files[0]}: {e}\")\n",
        "            else:\n",
        "                print(f\"‚ö†Ô∏è Kh√¥ng th·∫•y folder n√†o ch·ª©a t√™n '{target}'\")\n",
        "\n",
        "    if found_count == 4:\n",
        "        print(\"‚úÖ ƒê√£ v·∫Ω ƒë·ªß 4 lo·∫°i t√≠n hi·ªáu. H√£y quan s√°t h√¨nh b√™n d∆∞·ªõi!\")\n",
        "    else:\n",
        "        print(f\"‚ö†Ô∏è Ch·ªâ t√¨m th·∫•y {found_count}/4 lo·∫°i d·ªØ li·ªáu.\")\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "plot_raw_sample(DATA_PATH)"
      ],
      "metadata": {
        "id": "pRax--qKL_6Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "WINDOW_SIZE = 2048\n",
        "STRIDE = 1024\n",
        "BATCH_SIZE = 32\n",
        "\n",
        "class CWRU_Raw_Dataset(Dataset):\n",
        "    def __init__(self, root_dir):\n",
        "        self.data = []\n",
        "        self.labels = []\n",
        "        self.label_map = {\"Normal\": 0, \"Ball_007\": 1, \"Ball_014\": 2, \"Ball_021\": 3}\n",
        "\n",
        "        for folder in os.listdir(root_dir):\n",
        "            folder_path = os.path.join(root_dir, folder)\n",
        "            if not os.path.isdir(folder_path): continue\n",
        "\n",
        "            #Label\n",
        "            label = -1\n",
        "            for key, val in self.label_map.items():\n",
        "                if key in folder:\n",
        "                    label = val\n",
        "                    break\n",
        "\n",
        "            if label != -1:\n",
        "                for file in os.listdir(folder_path):\n",
        "                    if file.endswith('.mat'):\n",
        "                        self._load_mat(os.path.join(folder_path, file), label)\n",
        "\n",
        "        self.data = torch.tensor(np.array(self.data), dtype=torch.float32).unsqueeze(1)\n",
        "        self.labels = torch.tensor(np.array(self.labels), dtype=torch.long)\n",
        "        print(f\"üì¶ Dataset Info: {self.data.shape} (M·∫´u, K√™nh, ƒê·ªô d√†i)\")\n",
        "\n",
        "    def _load_mat(self, path, label):\n",
        "        try:\n",
        "            mat = scipy.io.loadmat(path)\n",
        "            key = [k for k in mat.keys() if 'DE_time' in k][0]\n",
        "            sig = mat[key].flatten()\n",
        "            for i in range(0, len(sig) - WINDOW_SIZE, STRIDE):\n",
        "                self.data.append(sig[i : i + WINDOW_SIZE])\n",
        "                self.labels.append(label)\n",
        "        except: pass\n",
        "\n",
        "    def __len__(self): return len(self.data)\n",
        "    def __getitem__(self, idx): return self.data[idx], self.labels[idx]\n",
        "\n",
        "full_dataset = CWRU_Raw_Dataset(DATA_PATH)\n",
        "train_size = int(0.8 * len(full_dataset))\n",
        "test_size = len(full_dataset) - train_size\n",
        "train_set, test_set = torch.utils.data.random_split(full_dataset, [train_size, test_size])\n",
        "\n",
        "train_loader = DataLoader(train_set, batch_size=BATCH_SIZE, shuffle=True)\n",
        "test_loader = DataLoader(test_set, batch_size=BATCH_SIZE, shuffle=False)\n",
        "print(\"‚úÖ D·ªØ li·ªáu ƒë√£ s·∫µn s√†ng!\")"
      ],
      "metadata": {
        "id": "j2eAR0h6QLw7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "class RawCNN_1D(nn.Module):\n",
        "    def __init__(self, num_classes=4):\n",
        "        super(RawCNN_1D, self).__init__()\n",
        "        self.conv1 = nn.Conv1d(1, 16, 64, stride=2, padding=1)\n",
        "        self.bn1 = nn.BatchNorm1d(16)\n",
        "        self.conv2 = nn.Conv1d(16, 32, 32, stride=2, padding=1)\n",
        "        self.bn2 = nn.BatchNorm1d(32)\n",
        "        self.conv3 = nn.Conv1d(32, 64, 16, stride=2, padding=1)\n",
        "        self.bn3 = nn.BatchNorm1d(64)\n",
        "        self.pool = nn.MaxPool1d(2)\n",
        "        self.flatten = nn.Flatten()\n",
        "        self.fc1 = nn.Linear(1664, 128) # K√≠ch th∆∞·ªõc ƒë√£ fix chu·∫©n\n",
        "        self.dropout = nn.Dropout(0.5)\n",
        "        self.fc2 = nn.Linear(128, num_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.pool(F.relu(self.bn1(self.conv1(x))))\n",
        "        x = self.pool(F.relu(self.bn2(self.conv2(x))))\n",
        "        x = self.pool(F.relu(self.bn3(self.conv3(x))))\n",
        "        x = self.flatten(x)\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = self.dropout(x)\n",
        "        return self.fc2(x)\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model = RawCNN_1D(num_classes=4).to(device)\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "print(\"üöÄ B·∫Øt ƒë·∫ßu Train...\")\n",
        "for epoch in range(15):\n",
        "    model.train()\n",
        "    running_loss = 0.0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    for inputs, labels in train_loader:\n",
        "        inputs, labels = inputs.to(device), labels.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(inputs)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        running_loss += loss.item()\n",
        "        _, predicted = torch.max(outputs, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "    print(f\"Epoch {epoch+1}/15 | Loss: {running_loss/len(train_loader):.4f} | Acc: {100*correct/total:.2f}%\")"
      ],
      "metadata": {
        "id": "h3L4Cku_QRZi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.eval()\n",
        "all_preds = []\n",
        "all_labels = []\n",
        "\n",
        "print(\"üìä ƒêang ch·∫•m thi tr√™n t·∫≠p Test...\")\n",
        "with torch.no_grad():\n",
        "    for inputs, labels in test_loader:\n",
        "        inputs, labels = inputs.to(device), labels.to(device)\n",
        "        outputs = model(inputs)\n",
        "        _, predicted = torch.max(outputs, 1)\n",
        "        all_preds.extend(predicted.cpu().numpy())\n",
        "        all_labels.extend(labels.cpu().numpy())\n",
        "\n",
        "# T√≠nh Accuracy th·ª±c t·∫ø\n",
        "acc = 100 * sum(np.array(all_preds) == np.array(all_labels)) / len(all_labels)\n",
        "print(f\"üéØ ƒê·ªò CH√çNH X√ÅC TH·ª∞C T·∫æ (TEST): {acc:.2f}%\")\n",
        "\n",
        "# V·∫Ω Matrix\n",
        "cm = confusion_matrix(all_labels, all_preds)\n",
        "plt.figure(figsize=(8,6))\n",
        "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n",
        "            xticklabels=[\"Normal\", \"Ball_007\", \"Ball_014\", \"Ball_021\"],\n",
        "            yticklabels=[\"Normal\", \"Ball_007\", \"Ball_014\", \"Ball_021\"])\n",
        "plt.xlabel('D·ª± ƒëo√°n')\n",
        "plt.ylabel('Th·ª±c t·∫ø')\n",
        "plt.title('Confusion Matrix (K·∫øt qu·∫£ cu·ªëi c√πng)')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "0p9_5D-LQbuz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# FAN-END (FE)\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import DataLoader\n",
        "from sklearn.metrics import confusion_matrix\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "\n",
        "#Path\n",
        "FE_PATH = '/content/drive/My Drive/Bearing/FE_data'\n",
        "\n",
        "\n",
        "print(f\"üïµÔ∏è ƒêang qu√©t d·ªØ li·ªáu Fan-End t·∫°i: {FE_PATH}\")\n",
        "fe_dataset = CWRU_Raw_Dataset(FE_PATH)\n",
        "\n",
        "if len(fe_dataset) > 0:\n",
        "    # Batch size train\n",
        "    fe_loader = DataLoader(fe_dataset, batch_size=32, shuffle=False)\n",
        "\n",
        "\n",
        "    model.eval() # test\n",
        "    all_preds = []\n",
        "    all_labels = []\n",
        "    correct = 0\n",
        "    total = 0\n",
        "\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for inputs, labels in fe_loader:\n",
        "            inputs, labels = inputs.to(device), labels.to(device)\n",
        "\n",
        "            # ƒê∆∞a qua model DE c≈©\n",
        "            outputs = model(inputs)\n",
        "            _, predicted = torch.max(outputs, 1)\n",
        "\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "\n",
        "            all_preds.extend(predicted.cpu().numpy())\n",
        "            all_labels.extend(labels.cpu().numpy())\n",
        "\n",
        "\n",
        "    acc = 100 * correct / total\n",
        "    print(\"=\"*40)\n",
        "    print(f\"üò± K·∫æT QU·∫¢ FAN-END ACCURACY: {acc:.2f}%\")\n",
        "    print(\"=\"*40)\n",
        "\n",
        "\n",
        "    cm = confusion_matrix(all_labels, all_preds)\n",
        "    plt.figure(figsize=(8,6))\n",
        "    sns.heatmap(cm, annot=True, fmt='d', cmap='Reds',\n",
        "                xticklabels=[\"Normal\", \"Ball_007\", \"Ball_014\", \"Ball_021\"],\n",
        "                yticklabels=[\"Normal\", \"Ball_007\", \"Ball_014\", \"Ball_021\"])\n",
        "    plt.xlabel('Model d·ª± ƒëo√°n (D·ª±a tr√™n ki·∫øn th·ª©c DE)')\n",
        "    plt.ylabel('Th·ª±c t·∫ø (D·ªØ li·ªáu FE)')\n",
        "    plt.title(f'K·∫øt qu·∫£ Cross-Domain (Acc: {acc:.2f}%)')\n",
        "    plt.show()\n",
        "\n"
      ],
      "metadata": {
        "id": "zBLWwpA39PEO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Mount Drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "DATA_PATH = '/content/drive/My Drive/Bearing/FE_data'\n",
        "\n",
        "if os.path.exists(DATA_PATH):\n",
        "    print(f\"{DATA_PATH}\")\n",
        "    print(\"Fld:\", os.listdir(DATA_PATH))"
      ],
      "metadata": {
        "id": "YNE5zKYR_emG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_raw_sample(root_dir):\n",
        "    #Define\n",
        "    target_folders = [\"Normal\", \"Ball_007\", \"Ball_014\", \"Ball_021\"]\n",
        "\n",
        "    plt.figure(figsize=(15, 10))\n",
        "    plt.subplots_adjust(hspace=0.4)\n",
        "\n",
        "    found_count = 0\n",
        "\n",
        "    # Check fld\n",
        "    if os.path.exists(root_dir):\n",
        "        all_folders = os.listdir(root_dir)\n",
        "\n",
        "        for i, target in enumerate(target_folders):\n",
        "\n",
        "            folder_name = next((f for f in all_folders if target in f), None)\n",
        "\n",
        "            if folder_name:\n",
        "                folder_path = os.path.join(root_dir, folder_name)\n",
        "                # Get .mat\n",
        "                files = [f for f in os.listdir(folder_path) if f.endswith('.mat')]\n",
        "\n",
        "                if files:\n",
        "                    file_path = os.path.join(folder_path, files[0])\n",
        "                    try:\n",
        "\n",
        "                        mat = scipy.io.loadmat(file_path)\n",
        "                        key = [k for k in mat.keys() if 'DE_time' in k][0]\n",
        "                        signal = mat[key].flatten()\n",
        "\n",
        "                        #plt.subplot(2, 2, i + 1)\n",
        "                        plt.figure(figsize=(15, 5))\n",
        "                        plt.ylim(-2 , 2)\n",
        "                        plt.plot(signal[:12000])\n",
        "                        plt.title(f\"M·∫´u: {target} (File: {files[0]})\")\n",
        "                        plt.ylabel(\"Bi√™n ƒë·ªô (Amplitude)\")\n",
        "                        plt.grid(True)\n",
        "                        found_count += 1\n",
        "                    except Exception as e:\n",
        "                        print(f\"L·ªói ƒë·ªçc file {files[0]}: {e}\")\n",
        "            else:\n",
        "                print(f\"‚ö†Ô∏è Kh√¥ng th·∫•y folder n√†o ch·ª©a t√™n '{target}'\")\n",
        "\n",
        "    if found_count == 4:\n",
        "        print(\"‚úÖ ƒê√£ v·∫Ω ƒë·ªß 4 lo·∫°i t√≠n hi·ªáu. H√£y quan s√°t h√¨nh b√™n d∆∞·ªõi!\")\n",
        "    else:\n",
        "        print(f\"‚ö†Ô∏è Ch·ªâ t√¨m th·∫•y {found_count}/4 lo·∫°i d·ªØ li·ªáu.\")\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "plot_raw_sample(DATA_PATH)"
      ],
      "metadata": {
        "id": "8rWGx1Dv_HVs"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}